import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report
from sklearn.impute import SimpleImputer

# Set random seed for reproducibility
np.random.seed(42)

def load_and_explore_data():
    """Load and explore the dataset."""
    print("Loading data...")
    df = pd.read_csv('members_with_exercise_recommendations.csv')
    
    print(f"Dataset shape: {df.shape}")
    print("\nFirst few rows:")
    print(df.head())
    
    print("\nBasic statistics:")
    print(df.describe())
    
    print("\nMissing values:")
    print(df.isnull().sum())
    
    return df

def preprocess_data(df):
    """Preprocess the data for machine learning."""
    print("\nPreprocessing data...")
    
    # Drop columns that are not useful for prediction
    # We'll drop the recommended exercises and details as they were generated by our script
    df_ml = df.drop(['Recommended_Exercises', 'Exercise_Type_Details'], axis=1)
    
    # Check for missing values and handle them
    if df_ml.isnull().sum().sum() > 0:
        print("Handling missing values...")
        # For simplicity, we'll use median imputation for numeric columns
        numeric_cols = df_ml.select_dtypes(include=['int64', 'float64']).columns
        df_ml[numeric_cols] = df_ml[numeric_cols].fillna(df_ml[numeric_cols].median())
        
        # For categorical columns, fill with the most frequent value
        cat_cols = df_ml.select_dtypes(include=['object']).columns
        for col in cat_cols:
            df_ml[col] = df_ml[col].fillna(df_ml[col].mode()[0])
    
    return df_ml

def calories_burned_prediction(df):
    """Build a model to predict calories burned."""
    print("\n--- Calories Burned Prediction Model ---")
    
    # Define features and target
    X = df.drop(['Calories_Burned'], axis=1)
    y = df['Calories_Burned']
    
    # Identify numeric and categorical columns
    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
    categorical_cols = X.select_dtypes(include=['object']).columns
    
    # Create preprocessing steps for numeric and categorical data
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])
    
    # Combine preprocessing steps
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_cols),
            ('cat', categorical_transformer, categorical_cols)
        ])
    
    # Create and evaluate models
    models = {
        'Linear Regression': LinearRegression(),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)
    }
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    for name, model in models.items():
        # Create pipeline with preprocessing and model
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('model', model)
        ])
        
        # Train model
        print(f"\nTraining {name}...")
        pipeline.fit(X_train, y_train)
        
        # Make predictions
        y_pred = pipeline.predict(X_test)
        
        # Evaluate model
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        print(f"{name} Results:")
        print(f"Mean Squared Error: {mse:.2f}")
        print(f"RÂ² Score: {r2:.2f}")
        print(f"RMSE: {np.sqrt(mse):.2f}")
        
        # For Random Forest, show feature importance
        if name == 'Random Forest':
            # Get feature names after one-hot encoding
            feature_names = []
            for name, transformer, cols in preprocessor.transformers_:
                if name == 'cat':
                    # Get the one-hot encoded feature names
                    feature_names.extend(transformer.named_steps['onehot'].get_feature_names_out(cols))
                else:
                    feature_names.extend(cols)
            
            # Get feature importances
            importances = pipeline.named_steps['model'].feature_importances_
            
            # Sort feature importances in descending order
            indices = np.argsort(importances)[::-1]
            
            # Print the feature ranking
            print("\nFeature ranking:")
            for f in range(min(10, len(feature_names))):
                if f < len(indices):
                    print(f"{f+1}. {feature_names[indices[f]]} ({importances[indices[f]]:.4f})")
    
    return pipeline  # Return the last trained model

def workout_type_prediction(df):
    """Build a model to predict workout type."""
    print("\n--- Workout Type Prediction Model ---")
    
    # Define features and target
    X = df.drop(['Workout_Type', 'Calories_Burned'], axis=1)  # We'll exclude calories as it's highly correlated with workout type
    y = df['Workout_Type']
    
    # Identify numeric and categorical columns
    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
    categorical_cols = X.select_dtypes(include=['object']).columns
    
    # Create preprocessing steps
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])
    
    # Combine preprocessing steps
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_cols),
            ('cat', categorical_transformer, categorical_cols)
        ])
    
    # Create model
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    
    # Create pipeline
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Train model
    print("Training Random Forest Classifier...")
    pipeline.fit(X_train, y_train)
    
    # Make predictions
    y_pred = pipeline.predict(X_test)
    
    # Evaluate model
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"Accuracy: {accuracy:.2f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    
    return pipeline

def experience_level_prediction(df):
    """Build a model to predict experience level."""
    print("\n--- Experience Level Prediction Model ---")
    
    # Define features and target
    X = df.drop(['Experience_Level', 'Workout_Type'], axis=1)  # Exclude workout type as it might leak information
    y = df['Experience_Level']
    
    # Identify numeric and categorical columns
    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
    categorical_cols = X.select_dtypes(include=['object']).columns
    
    # Create preprocessing steps
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])
    
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])
    
    # Combine preprocessing steps
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_cols),
            ('cat', categorical_transformer, categorical_cols)
        ])
    
    # Create model
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    
    # Create pipeline
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Train model
    print("Training Random Forest Classifier...")
    pipeline.fit(X_train, y_train)
    
    # Make predictions
    y_pred = pipeline.predict(X_test)
    
    # Evaluate model
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"Accuracy: {accuracy:.2f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    
    return pipeline

def visualize_data(df):
    """Create visualizations of the data."""
    print("\nCreating visualizations...")
    
    # Create a directory for visualizations
    import os
    if not os.path.exists('visualizations'):
        os.makedirs('visualizations')
    
    # 1. Distribution of workout types
    plt.figure(figsize=(10, 6))
    workout_counts = df['Workout_Type'].value_counts()
    sns.barplot(x=workout_counts.index, y=workout_counts.values)
    plt.title('Distribution of Workout Types')
    plt.xlabel('Workout Type')
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('visualizations/workout_types.png')
    
    # 2. Calories burned by workout type
    plt.figure(figsize=(10, 6))
    sns.boxplot(x='Workout_Type', y='Calories_Burned', data=df)
    plt.title('Calories Burned by Workout Type')
    plt.xlabel('Workout Type')
    plt.ylabel('Calories Burned')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('visualizations/calories_by_workout.png')
    
    # 3. Correlation heatmap
    plt.figure(figsize=(12, 10))
    numeric_df = df.select_dtypes(include=['int64', 'float64'])
    correlation = numeric_df.corr()
    mask = np.triu(np.ones_like(correlation, dtype=bool))
    sns.heatmap(correlation, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', square=True, linewidths=.5)
    plt.title('Correlation Heatmap')
    plt.tight_layout()
    plt.savefig('visualizations/correlation_heatmap.png')
    
    # 4. Age distribution by gender
    plt.figure(figsize=(10, 6))
    sns.histplot(data=df, x='Age', hue='Gender', multiple='stack', bins=20)
    plt.title('Age Distribution by Gender')
    plt.xlabel('Age')
    plt.ylabel('Count')
    plt.tight_layout()
    plt.savefig('visualizations/age_by_gender.png')
    
    # 5. BMI distribution
    plt.figure(figsize=(10, 6))
    sns.histplot(data=df, x='BMI', bins=20)
    plt.title('BMI Distribution')
    plt.xlabel('BMI')
    plt.ylabel('Count')
    plt.tight_layout()
    plt.savefig('visualizations/bmi_distribution.png')
    
    print("Visualizations saved to 'visualizations' directory.")

def make_predictions(calories_model, workout_model, experience_model):
    """Make predictions for a new gym member."""
    print("\n--- Making Predictions for a New Gym Member ---")

    # Create a sample new member
    new_member = pd.DataFrame({
        'Age': [30],
        'Gender': ['Male'],
        'Weight (kg)': [75.0],
        'Height (m)': [1.75],
        'Max_BPM': [180],
        'Avg_BPM': [150],
        'Resting_BPM': [65],
        'Session_Duration (hours)': [1.0],
        'Fat_Percentage': [20.0],
        'Water_Intake (liters)': [2.5],
        'Workout_Frequency (days/week)': [3],
        'BMI': [24.5],
        # Dummy values for required columns
        'Workout_Type': ['Strength'],  
        'Experience_Level': [2],       
        'Calories_Burned': [0]         
    })

    # Prepare input for the calories prediction model
    new_member_calories = new_member.drop(['Calories_Burned'], axis=1)

    # Predict calories burned
    predicted_calories = calories_model.predict(new_member_calories)

    # Ensure it is a single scalar value
    predicted_calories = float(predicted_calories[0])  # Convert first element to a float

    print("\nPredictions for new gym member:")
    print(f"Predicted calories burned: {predicted_calories:.2f}")

    return predicted_calories  # Return a scalar float instead of an array


def generate_meal_recommendations(predicted_calories, nutrient_file, user_goal=None):
    """Generate meal recommendations based on predicted calories burned and user's goal."""
    # Read nutrient data
    nutrient_data = pd.read_csv(nutrient_file)
    
    # Calculate target calories based on goal
    if user_goal == "Muscle Building":
        target_calories = predicted_calories + 500  # Caloric surplus for muscle growth
        protein_ratio = 0.3  # 30% protein
        carb_ratio = 0.5    # 50% carbs
        fat_ratio = 0.2     # 20% fat
    elif user_goal == "Weight Loss":
        target_calories = predicted_calories - 500  # Caloric deficit for weight loss
        protein_ratio = 0.4  # 40% protein
        carb_ratio = 0.3    # 30% carbs
        fat_ratio = 0.3     # 30% fat
    elif user_goal == "Cardiovascular Health":
        target_calories = predicted_calories  # Maintenance calories
        protein_ratio = 0.25  # 25% protein
        carb_ratio = 0.55    # 55% carbs
        fat_ratio = 0.2      # 20% fat
    else:  # General Fitness or Flexibility
        target_calories = predicted_calories  # Maintenance calories
        protein_ratio = 0.3  # 30% protein
        carb_ratio = 0.45   # 45% carbs
        fat_ratio = 0.25    # 25% fat
    
    # Define meal recommendations with goal-specific portions
    meal_plan = {
        'Grilled Chicken Breast': {
            'Calories': 165,
            'Protein': 31,
            'Carbs': 0,
            'Fiber': 0,
            'Servings': 2 if user_goal == "Muscle Building" else 1.5
        },
        'Brown Rice': {
            'Calories': 216,
            'Protein': 5,
            'Carbs': 45,
            'Fiber': 3.5,
            'Servings': 2 if user_goal in ["Muscle Building", "Cardiovascular Health"] else 1
        },
        'Sweet Potato': {
            'Calories': 180,
            'Protein': 4,
            'Carbs': 41,
            'Fiber': 6.6,
            'Servings': 1.5 if user_goal in ["Muscle Building", "Cardiovascular Health"] else 1
        },
        'Greek Yogurt': {
            'Calories': 133,
            'Protein': 11,
            'Carbs': 3.8,
            'Fiber': 0,
            'Servings': 2 if user_goal == "Muscle Building" else 1
        },
        'Mixed Nuts': {
            'Calories': 160,
            'Protein': 6,
            'Carbs': 8,
            'Fiber': 3,
            'Servings': 1.5 if user_goal == "Weight Loss" else 1
        },
        'Protein Shake': {
            'Calories': 120,
            'Protein': 24,
            'Carbs': 3,
            'Fiber': 0,
            'Servings': 2 if user_goal == "Muscle Building" else 1
        },
        'Quinoa': {
            'Calories': 222,
            'Protein': 8,
            'Carbs': 39,
            'Fiber': 5,
            'Servings': 1.5 if user_goal in ["Muscle Building", "Cardiovascular Health"] else 1
        },
        'Salmon': {
            'Calories': 208,
            'Protein': 22,
            'Carbs': 0,
            'Fiber': 0,
            'Servings': 1.5 if user_goal in ["Muscle Building", "Weight Loss"] else 1
        },
        'Broccoli': {
            'Calories': 55,
            'Protein': 3.7,
            'Carbs': 11.2,
            'Fiber': 5.2,
            'Servings': 2
        },
        'Eggs': {
            'Calories': 155,
            'Protein': 13,
            'Carbs': 1.1,
            'Fiber': 0,
            'Servings': 3 if user_goal == "Muscle Building" else 2
        }
    }
    
    return meal_plan



def main():
    """Main function to run the machine learning pipeline."""
    print("=== Gym Member Machine Learning Models ===")

    # Load and preprocess data
    df = load_and_explore_data()
    df_ml = preprocess_data(df)

    # Visualize data
    visualize_data(df)

    # Train models
    calories_model = calories_burned_prediction(df_ml)
    workout_model = workout_type_prediction(df_ml)
    experience_model = experience_level_prediction(df_ml)

    # Get the predicted calories burned
    predicted_calories = make_predictions(calories_model, workout_model, experience_model)

    # Generate meal recommendations based on predicted calories
    nutrient_file = "nutrients_csvfile.csv"
    generate_meal_recommendations(predicted_calories, nutrient_file)

    print("\nDone!")




if __name__ == "__main__":
    main() 
    